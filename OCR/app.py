# app

# !/usr/bin/env python3
"""
Unified OCR Server ‚Äî –ª–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –±–µ–∑ Docker
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏: deepseek-ocr, deepseek-ocr2, paddleocr-vl-1.5, glm-ocr
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (PDF, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è) —Å –º–µ—Ç—Ä–∏–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
"""

from contextlib import asynccontextmanager
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import io
import torch
import sys
import os
import time
from typing import List, Tuple, Optional

# –ò–º–ø–æ—Ä—Ç –ª–æ–≥–≥–µ—Ä–∞ –∏ —É—Ç–∏–ª–∏—Ç
from utils import logger, PDFHandler, confidence_calculator

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ PATH
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –º–æ–¥–µ–ª–µ–π (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)
models = {}
model_load_times = {}  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–≥—Ä—É–∑–∫–∏
pdf_handler = PDFHandler(dpi=300)  # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ PDF


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Lifespan –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ/–æ—Å—Ç–∞–Ω–æ–≤–∫–µ —Å–µ—Ä–≤–µ—Ä–∞.
    """
    # ===== ON STARTUP =====
    logger.info("=" * 70)
    logger.info("üöÄ Unified OCR Server –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    logger.info(f"   PyTorch CUDA: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        logger.info(
            f"   GPU: {torch.cuda.get_device_name(0)} | VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")
    else:
        logger.warning("‚ö†Ô∏è  GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω! –°–µ—Ä–≤–µ—Ä –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ CPU (–º–µ–¥–ª–µ–Ω–Ω–æ)")
    logger.info("=" * 70)

    logger.info("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    logger.info("  ‚Ä¢ deepseek-ocr      (1.3B) ‚Äî –±–∞–∑–æ–≤—ã–π OCR")
    logger.info("  ‚Ä¢ deepseek-ocr2     (3B)   ‚Äî —Ç–∞–±–ª–∏—Ü—ã + —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
    logger.info("  ‚Ä¢ paddleocr-vl-1.5  (0.9B) ‚Äî –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
    logger.info("  ‚Ä¢ glm-ocr           (0.9B) ‚Äî –±—ã—Å—Ç—Ä—ã–π —á–∏—Å—Ç—ã–π OCR")

    logger.info("\nüåê API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:")
    logger.info("  GET  /              ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ—Ä–≤–µ—Ä–µ")
    logger.info("  GET  /models        ‚Äî —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
    logger.info("  POST /ocr           ‚Äî —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ PDF)")
    logger.info("  GET  /docs          ‚Äî –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (Swagger)")
    logger.info("=" * 70)

    yield  # –°–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–¥–µ—Å—å

    # ===== ON SHUTDOWN =====
    logger.info("\n" + "=" * 70)
    logger.info("üõë Unified OCR Server –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è...")

    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å –º–æ–¥–µ–ª–µ–π
    global models
    if models:
        logger.info(f"–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏: {len(models)} –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
        for model_name in list(models.keys()):
            del models[model_name]
        torch.cuda.empty_cache()
        logger.info("‚úÖ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")

    logger.info("=" * 70 + "\n")


# –°–æ–∑–¥–∞—ë–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
app = FastAPI(
    title="Unified OCR Server",
    version="1.0",
    lifespan=lifespan
)

# CORS –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def validate_file_type(file_bytes: bytes, filename: str) -> Optional[str]:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞

    Args:
        file_bytes: –±–∞–π—Ç—ã —Ñ–∞–π–ª–∞
        filename: –∏–º—è —Ñ–∞–π–ª–∞

    Returns:
        "pdf" | "image" | None (–µ—Å–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
    """
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    ext = filename.lower().split('.')[-1]

    if ext in ['pdf']:
        return "pdf"
    elif ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff', 'webp']:
        return "image"
    else:
        return None


def process_single_image_with_confidence(
        image: Image.Image,
        model_name: str,
        prompt: str,
        return_confidence: bool
) -> Tuple[str, Optional[float]]:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å —Ä–∞—Å—á—ë—Ç–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

    Args:
        image: PIL Image
        model_name: –∏–º—è –º–æ–¥–µ–ª–∏
        prompt: –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
        return_confidence: –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –º–µ—Ç—Ä–∏–∫—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

    Returns:
        (—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∏–ª–∏ None)
    """
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ
    if model_name not in models:
        logger.info(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ '{model_name}'...")
        load_start = time.time()

        try:
            if model_name == "deepseek-ocr":
                from models import DeepSeekOCRModel
                models[model_name] = DeepSeekOCRModel()
            elif model_name == "deepseek-ocr2":
                from models import DeepSeekOCR2Model
                models[model_name] = DeepSeekOCR2Model()
            elif model_name == "paddleocr-vl-1.5":
                from models import PaddleOCRVLModel
                models[model_name] = PaddleOCRVLModel()
            elif model_name == "glm-ocr":
                from models import GLMOCRModel
                models[model_name] = GLMOCRModel()

            load_time = time.time() - load_start
            model_load_times[model_name] = load_time
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å '{model_name}' –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f} —Å–µ–∫")

        except Exception as e:
            error_msg = str(e)
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ '{model_name}': {error_msg}", exc_info=True)

            if "404 Client Error" in error_msg and "deepseek-ocr2" in model_name:
                error_msg = "DeepSeek-OCR 2 –µ—â—ë –Ω–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –Ω–∞ Hugging Face."
            elif "trust_remote_code" in error_msg:
                error_msg = "–¢—Ä–µ–±—É–µ—Ç—Å—è —è–≤–Ω–æ —Ä–∞–∑—Ä–µ—à–∏—Ç—å trust_remote_code=True –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏"

            raise RuntimeError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {error_msg}")

    # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
    try:
        result, confidence = models[model_name].infer(image, prompt, return_confidence)
        return result, confidence
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {str(e)}", exc_info=True)
        raise


@app.get("/")
async def root():
    """–ü—Ä–æ—Å—Ç–∞—è –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    logger.debug("–ó–∞–ø—Ä–æ—Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
    return {
        "message": "Unified OCR Server",
        "version": "1.0",
        "api_docs": "/docs",
        "models": "/models",
        "status": "running"
    }


@app.get("/models")
async def list_models():
    """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    logger.info("–ó–∞–ø—Ä–æ—Å —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π")

    available = [
        "deepseek-ocr",
        "deepseek-ocr2",
        "paddleocr-vl-1.5",
        "glm-ocr"
    ]

    loaded_info = {}
    for model_name in models.keys():
        load_time = model_load_times.get(model_name, "N/A")
        loaded_info[model_name] = {
            "status": "loaded",
            "load_time_sec": round(load_time, 2) if isinstance(load_time, float) else load_time
        }

    return {
        "available_models": available,
        "loaded_models": list(models.keys()),
        "loaded_models_details": loaded_info,
        "cuda_available": torch.cuda.is_available(),
        "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,
        "total_loaded": len(models)
    }


@app.post("/ocr")
async def ocr_inference(
        model_name: str = Form(...),
        image: UploadFile = File(...),
        prompt: str = Form("Extract all text"),
        return_confidence: bool = Form(True)
):
    """
    –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
      model_name: deepseek-ocr | deepseek-ocr2 | paddleocr-vl-1.5 | glm-ocr
      image: —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (jpg, png) –∏–ª–∏ PDF
      prompt: –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
      return_confidence: –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –º–µ—Ç—Ä–∏–∫—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é true)
    """
    start_time = time.time()
    request_id = f"req_{int(start_time * 1000)}"

    logger.info(f"[{request_id}] üì• –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å | –ú–æ–¥–µ–ª—å: {model_name} | –§–∞–π–ª: {image.filename}")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    valid_models = ["deepseek-ocr", "deepseek-ocr2", "paddleocr-vl-1.5", "glm-ocr"]
    if model_name not in valid_models:
        error_msg = f"–ù–µ–≤–µ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å '{model_name}'. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {', '.join(valid_models)}"
        logger.error(f"[{request_id}] ‚ùå {error_msg}")
        raise HTTPException(status_code=400, detail=error_msg)

    # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    try:
        file_bytes = await image.read()
        file_type = validate_file_type(file_bytes, image.filename)

        if file_type is None:
            raise HTTPException(
                status_code=400,
                detail=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {image.filename}. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: PDF, JPG, PNG, BMP, TIFF, WEBP"
            )

        logger.debug(f"[{request_id}] üìÅ –¢–∏–ø —Ñ–∞–π–ª–∞: {file_type.upper()} | –†–∞–∑–º–µ—Ä: {len(file_bytes) / 1024:.1f} KB")

    except Exception as e:
        logger.error(f"[{request_id}] ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}", exc_info=True)
        raise HTTPException(status_code=400, detail=f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
    try:
        if file_type == "pdf":
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ PDF
            logger.info(f"[{request_id}] üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ PDF...")

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            try:
                pages = pdf_handler.pdf_bytes_to_images(file_bytes)
            except ValueError as e:
                raise HTTPException(status_code=400, detail=str(e))

            if not pages:
                raise HTTPException(status_code=400, detail="PDF —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü")

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            results = []
            page_confidences = []

            for page_num, page_image in pages:
                page_start = time.time()
                logger.info(f"[{request_id}] üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{len(pages)}...")

                try:
                    text, confidence = process_single_image_with_confidence(
                        page_image, model_name, prompt, return_confidence
                    )
                    page_confidences.append(confidence if confidence is not None else 0.5)

                    results.append({
                        "page_number": page_num,
                        "text": text,
                        "confidence": confidence,
                        "timing_seconds": round(time.time() - page_start, 2)
                    })

                    logger.info(
                        f"[{request_id}] ‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∑–∞ {time.time() - page_start:.2f} —Å–µ–∫" +
                        (f" | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}" if confidence else ""))

                except Exception as e:
                    logger.error(f"[{request_id}] ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {str(e)}", exc_info=True)
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
                    results.append({
                        "page_number": page_num,
                        "error": str(e),
                        "text": None,
                        "confidence": None,
                        "timing_seconds": round(time.time() - page_start, 2)
                    })
                    page_confidences.append(0.1)  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–µ

            # –†–∞—Å—á—ë—Ç –æ–±—â–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º –¥–ª—è –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏)
            overall_confidence = min(page_confidences) if page_confidences else None

            total_time = time.time() - start_time

            logger.info(f"[{request_id}] ‚úÖ PDF –æ–±—Ä–∞–±–æ—Ç–∞–Ω | –í—Å–µ–≥–æ: {total_time:.2f} —Å–µ–∫ | –°—Ç—Ä–∞–Ω–∏—Ü: {len(results)}")

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
            combined_text = "\n\n--- –°–¢–†–ê–ù–ò–¶–ê –†–ê–ó–î–ï–õ–ò–¢–ï–õ–¨ ---\n\n".join(
                f"[–°—Ç—Ä–∞–Ω–∏—Ü–∞ {r['page_number']}]\n{r['text']}"
                for r in results if r.get('text')
            )

            return {
                "model": model_name,
                "prompt": prompt,
                "file_type": "pdf",
                "total_pages": len(pages),
                "processed_pages": len([r for r in results if r.get('text')]),
                "pages": results,
                "combined_text": combined_text,
                "confidence": overall_confidence,
                "confidence_per_page": page_confidences,
                "status": "success",
                "timing": {
                    "total_seconds": round(total_time, 2),
                    "pages": [r.get('timing_seconds', 0) for r in results]
                },
                "request_id": request_id
            }

        else:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            logger.debug(f"[{request_id}] üñºÔ∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")

            try:
                img = Image.open(io.BytesIO(file_bytes)).convert("RGB")
            except Exception as e:
                logger.error(f"[{request_id}] ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}", exc_info=True)
                raise HTTPException(status_code=400, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")

            # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
            infer_start = time.time()
            text, confidence = process_single_image_with_confidence(
                img, model_name, prompt, return_confidence
            )
            infer_time = time.time() - infer_start

            total_time = time.time() - start_time

            logger.info(f"[{request_id}] ‚úÖ –£—Å–ø–µ—à–Ω–æ | –ò–Ω—Ñ–µ—Ä–µ–Ω—Å: {infer_time:.2f} —Å–µ–∫ | –í—Å–µ–≥–æ: {total_time:.2f} —Å–µ–∫" +
                        (f" | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}" if confidence else ""))
            logger.debug(f"[{request_id}] üìù –†–µ–∑—É–ª—å—Ç–∞—Ç (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {text[:100]}...")

            return {
                "model": model_name,
                "prompt": prompt,
                "file_type": "image",
                "text": text,
                "confidence": confidence,
                "status": "success",
                "timing": {
                    "inference_seconds": round(infer_time, 2),
                    "total_seconds": round(total_time, 2)
                },
                "request_id": request_id
            }

    except Exception as e:
        logger.error(f"[{request_id}] ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")


if __name__ == "__main__":
    import uvicorn

    logger.info("\nüöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ http://localhost:8000")
    logger.info("   –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8000/docs\n")

    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="warning")