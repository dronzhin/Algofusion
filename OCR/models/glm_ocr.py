from transformers import AutoProcessor, AutoModelForImageTextToText
import torch
from PIL import Image
import warnings
from utils import logger
import time


class GLMOCRModel:
    def __init__(self):
        logger.info("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ GLM-OCR 0.9B (zai-org)...")

        try:
            start_time = time.time()

            # –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è transformers
            warnings.filterwarnings("ignore", category=FutureWarning)

            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
            self.model = AutoModelForImageTextToText.from_pretrained(
                "zai-org/GLM-OCR",
                torch_dtype=torch.float16,
                device_map="auto",
                trust_remote_code=True
            )

            self.processor = AutoProcessor.from_pretrained(
                "zai-org/GLM-OCR",
                trust_remote_code=True
            )

            load_time = time.time() - start_time
            device = next(self.model.parameters()).device

            logger.info(f"‚úÖ GLM-OCR 0.9B –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f} —Å–µ–∫ | –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
            logger.debug(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in self.model.parameters()) / 1e9:.1f}B")

        except ImportError as e:
            if "accelerate" in str(e):
                logger.error(
                    "‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'accelerate' –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å device_map.\n"
                    "   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install accelerate"
                )
            raise
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ GLM-OCR: {str(e)}", exc_info=True)
            raise

    def infer(self, image: Image.Image, prompt: str = "Text Recognition:", return_confidence: bool = False) -> tuple:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

        Args:
            image: PIL Image –≤ —Ñ–æ—Ä–º–∞—Ç–µ RGB
            prompt: –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è "Text Recognition:")
            return_confidence: –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –º–µ—Ç—Ä–∏–∫—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

        Returns:
            (—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∏–ª–∏ None)
        """
        start_time = time.time()

        try:
            logger.debug(f"üìù GLM-OCR –∏–Ω—Ñ–µ—Ä–µ–Ω—Å | –ü—Ä–æ–º–ø—Ç: {prompt[:50]}...")
            logger.debug(f"   –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.size} | –§–æ—Ä–º–∞—Ç: {image.mode}")

            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ —á–∞—Ç–∞ –ë–ï–ó –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            messages = [{
                "role": "user",
                "content": [
                    {"type": "image"},  # ‚Üê –¢–æ–ª—å–∫–æ —Ç–∏–ø, –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    {"type": "text", "text": prompt}
                ]
            }]

            # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¢–û–õ–¨–ö–û —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä images
            inputs = self.processor.apply_chat_template(
                messages,
                tokenize=True,
                add_generation_prompt=True,
                return_dict=True,
                return_tensors="pt",
                images=image  # ‚Üê –ï–î–ò–ù–°–¢–í–ï–ù–ù–û–ï –º–µ—Å—Ç–æ –ø–µ—Ä–µ–¥–∞—á–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            ).to(self.model.device)

            # –£–±–∏—Ä–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –ø–æ–ª—è
            inputs.pop("token_type_ids", None)

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
            with torch.no_grad():
                if return_confidence:
                    output = self.model.generate(
                        **inputs,
                        max_new_tokens=2048,
                        output_scores=True,
                        return_dict_in_generate=True,
                        do_sample=False,
                        temperature=0.0
                    )
                    generated_ids = output.sequences[0]
                    scores = output.scores
                else:
                    generated_ids = self.model.generate(
                        **inputs,
                        max_new_tokens=2048,
                        do_sample=False,
                        temperature=0.0
                    )[0]
                    scores = None

            # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
            output_text = self.processor.decode(
                generated_ids[inputs["input_ids"].shape[1]:],
                skip_special_tokens=True
            )

            result = output_text.strip()
            infer_time = time.time() - start_time

            # –†–∞—Å—á—ë—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence = None
            if return_confidence and scores is not None:
                from utils import confidence_calculator
                token_conf, _ = confidence_calculator.calculate_from_logits(
                    generated_ids,
                    scores,
                    inputs["input_ids"].shape[1]
                )
                heuristic_conf = confidence_calculator.calculate_heuristic(result, image.size)
                confidence = confidence_calculator.combine_confidences(
                    token_conf,
                    heuristic_conf,
                    has_token_scores=True
                )
                logger.debug(
                    f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: —Ç–æ–∫–µ–Ω–Ω–∞—è={token_conf:.2f}, —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è={heuristic_conf:.2f}, –∏—Ç–æ–≥–æ–≤–∞—è={confidence:.2f}")

            logger.info(f"‚úÖ GLM-OCR –∑–∞–≤–µ—Ä—à–µ–Ω–∞ | –í—Ä–µ–º—è: {infer_time:.2f} —Å–µ–∫" +
                        (f" | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}" if confidence else ""))
            logger.debug(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {result[:100]}...")

            return result, confidence

        except TypeError as e:
            if "multiple values for keyword argument 'images'" in str(e):
                logger.error(
                    "‚ùå –û—à–∏–±–∫–∞: –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ 'images' –≤ apply_chat_template.\n"
                    "   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –¢–û–õ–¨–ö–û —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä 'images',\n"
                    "   –∞ –≤ messages.content –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ {'type': 'image'} –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö."
                )
            raise
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ GLM-OCR: {str(e)}", exc_info=True)
            raise