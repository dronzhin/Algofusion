# models/paddleocr_vl.py

"""
PaddleOCR-VL-1.5 –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö (–∫–∏—Ç–∞–π—Å–∫–∏–π, —è–ø–æ–Ω—Å–∫–∏–π, –∫–æ—Ä–µ–π—Å–∫–∏–π)
"""

from paddlenlp.transformers import AutoTokenizer, AutoModelForCausalLM
from paddlenlp.transformers.image_processing_paddleocr_vl import PaddleOCRVLImageProcessor
import paddle
from PIL import Image
import numpy as np
from utils import logger
import time
from typing import Tuple, Optional


class PaddleOCRVLModel:
    def __init__(self):
        logger.info("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ PaddleOCR-VL-1.5...")

        try:
            start_time = time.time()

            self.model = AutoModelForCausalLM.from_pretrained(
                "PaddlePaddle/PaddleOCR-VL-1.5",
                dtype="float16"
            )
            self.tokenizer = AutoTokenizer.from_pretrained("PaddlePaddle/PaddleOCR-VL-1.5")
            self.image_processor = PaddleOCRVLImageProcessor.from_pretrained("PaddlePaddle/PaddleOCR-VL-1.5")

            load_time = time.time() - start_time

            logger.info(f"‚úÖ PaddleOCR-VL-1.5 –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f} —Å–µ–∫")
            logger.debug(f"   GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {paddle.is_compiled_with_cuda()}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ PaddleOCR-VL-1.5: {str(e)}", exc_info=True)
            raise

    def infer(self, image: Image.Image, prompt: str = "Extract all text", return_confidence: bool = False) -> Tuple[str, Optional[float]]:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

        Args:
            image: PIL Image –≤ —Ñ–æ—Ä–º–∞—Ç–µ RGB
            prompt: –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
            return_confidence: –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –º–µ—Ç—Ä–∏–∫—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (—Ç–æ–ª—å–∫–æ —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è)

        Returns:
            (—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∏–ª–∏ None)
        """
        start_time = time.time()

        try:
            logger.debug(f"üìù PaddleOCR-VL-1.5 –∏–Ω—Ñ–µ—Ä–µ–Ω—Å | –ü—Ä–æ–º–ø—Ç: {prompt[:50]}...")
            logger.debug(f"   –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.size} | –§–æ—Ä–º–∞—Ç: {image.mode}")

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PIL ‚Üí numpy
            image_np = np.array(image)

            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            inputs = self.image_processor(images=image_np, return_tensors="pd")
            text_inputs = self.tokenizer(prompt, return_tensors="pd")
            inputs.update(text_inputs)

            # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
            with paddle.no_grad():
                output = self.model.generate(**inputs, max_length=1024)

            result = self.tokenizer.decode(output[0], skip_special_tokens=True)

            # –¢–æ–ª—å–∫–æ —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –ª–æ–≥–∏—Ç–∞–º)
            confidence = None
            if return_confidence:
                from utils import confidence_calculator
                confidence = confidence_calculator.calculate_heuristic(result, image.size)
                logger.debug(f"   –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}")

            infer_time = time.time() - start_time
            logger.info(f"‚úÖ PaddleOCR-VL-1.5 –∑–∞–≤–µ—Ä—à–µ–Ω–∞ | –í—Ä–µ–º—è: {infer_time:.2f} —Å–µ–∫" +
                       (f" | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}" if confidence else ""))
            logger.debug(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {result[:100]}...")

            return result, confidence

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ PaddleOCR-VL-1.5: {str(e)}", exc_info=True)
            raise